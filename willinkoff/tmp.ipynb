{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [1, 2, 3]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[1, 2, 3,]] + [[1, 2, 3,]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import hmean\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from subcluster_adacos import SCAdaCos\n",
    "from mixup_layer_simu import MixupLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MagnitudeSpectrogram(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Compute magnitude spectrograms.\n",
    "    https://towardsdatascience.com/how-to-easily-process-audio-on-your-gpu-with-tensorflow-2d9d91360f06\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sample_rate, fft_size, hop_size, f_min=0.0, f_max=None, **kwargs):\n",
    "        super(MagnitudeSpectrogram, self).__init__(**kwargs)\n",
    "        self.sample_rate = sample_rate\n",
    "        self.fft_size = fft_size\n",
    "        self.hop_size = hop_size\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max if f_max else sample_rate / 2\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(MagnitudeSpectrogram, self).build(input_shape)\n",
    "\n",
    "    def call(self, waveforms):\n",
    "        spectrograms = tf.signal.stft(waveforms,\n",
    "                                      frame_length=self.fft_size,\n",
    "                                      frame_step=self.hop_size,\n",
    "                                      pad_end=False)\n",
    "        magnitude_spectrograms = tf.abs(spectrograms)\n",
    "        magnitude_spectrograms = tf.expand_dims(magnitude_spectrograms, 3)\n",
    "        return magnitude_spectrograms\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'fft_size': self.fft_size,\n",
    "            'hop_size': self.hop_size,\n",
    "            'sample_rate': self.sample_rate,\n",
    "            'f_min': self.f_min,\n",
    "            'f_max': self.f_max,\n",
    "        }\n",
    "        config.update(super(MagnitudeSpectrogram, self).get_config())\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_emb_cnn(num_classes, raw_dim, n_subclusters, use_bias=False):\n",
    "\n",
    "    data_input = tf.keras.layers.Input(shape=(raw_dim, 1), dtype='float32')\n",
    "    label_input = tf.keras.layers.Input(shape=(num_classes), dtype='float32')\n",
    "\n",
    "    y = label_input\n",
    "    x = data_input\n",
    "\n",
    "    l2_weight_decay = tf.keras.regularizers.l2(1e-5)\n",
    "    \n",
    "    x_mix = x\n",
    "    # x_mix, y = MixupLayer(prob=0.5)([x_mix, y])\n",
    "\n",
    "    # FFT\n",
    "    x = tf.keras.layers.Lambda(lambda x: tf.math.abs(tf.signal.fft(tf.complex(x[:, :, 0], tf.zeros_like(x[:, :, 0])))[:, :int(raw_dim / 2)]))(x_mix)\n",
    "    x = tf.keras.layers.Reshape((-1,1))(x)\n",
    "    x = tf.keras.layers.Conv1D(128, 256, strides=64, activation='linear', padding='same',\n",
    "                               kernel_regularizer=l2_weight_decay, use_bias=use_bias)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Conv1D(128, 64, strides=32, activation='linear', padding='same',\n",
    "                               kernel_regularizer=l2_weight_decay, use_bias=use_bias)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Conv1D(128, 16, strides=4, activation='linear', padding='same',\n",
    "                               kernel_regularizer=l2_weight_decay, use_bias=use_bias)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(128, kernel_regularizer=l2_weight_decay, use_bias=use_bias)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Dense(128, kernel_regularizer=l2_weight_decay, use_bias=use_bias)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Dense(128, kernel_regularizer=l2_weight_decay, use_bias=use_bias)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Dense(128, kernel_regularizer=l2_weight_decay, use_bias=use_bias)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    emb_fft = tf.keras.layers.Dense(128, name='emb_fft', kernel_regularizer=l2_weight_decay, use_bias=use_bias)(x)\n",
    "\n",
    "    # magnitude\n",
    "    x = tf.keras.layers.Reshape((raw_dim,))(x_mix)\n",
    "    x = MagnitudeSpectrogram(16000, 1024, 512, f_max=8000, f_min=200)(x)\n",
    "    x = tf.keras.layers.Lambda(lambda x: x-tf.math.reduce_mean(x, axis=1, keepdims=True))(x) # CMN-like normalization\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-2)(x)\n",
    "\n",
    "    # first block\n",
    "    x = tf.keras.layers.Conv2D(16, 7, strides=2, activation='linear', padding='same',\n",
    "                               kernel_regularizer=l2_weight_decay, use_bias=use_bias)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "    # second block\n",
    "    xr = tf.keras.layers.ReLU()(x)\n",
    "    xr = tf.keras.layers.Conv2D(16, 3, activation='linear', padding='same', kernel_regularizer=l2_weight_decay, use_bias=use_bias)(xr)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    xr = tf.keras.layers.ReLU()(xr)\n",
    "    xr = tf.keras.layers.Conv2D(16, 3, activation='linear', padding='same', kernel_regularizer=l2_weight_decay, use_bias=use_bias)(xr)\n",
    "    x = tf.keras.layers.Add()([x, xr])\n",
    "    \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    xr = tf.keras.layers.ReLU()(x)\n",
    "    xr = tf.keras.layers.Conv2D(16, 3, activation='linear', padding='same', kernel_regularizer=l2_weight_decay, use_bias=use_bias)(xr)\n",
    "    xr = tf.keras.layers.ReLU()(xr)\n",
    "    xr = tf.keras.layers.BatchNormalization()(xr)\n",
    "    xr = tf.keras.layers.Conv2D(16, 3, activation='linear', padding='same', kernel_regularizer=l2_weight_decay, use_bias=use_bias)(xr)\n",
    "    x = tf.keras.layers.Add()([x, xr])\n",
    "\n",
    "    # third block\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    xr = tf.keras.layers.ReLU()(x)\n",
    "    xr = tf.keras.layers.Conv2D(32, 3, strides=(2, 2), activation='linear', padding='same',\n",
    "                                kernel_regularizer=l2_weight_decay, use_bias=use_bias)(xr)\n",
    "    xr = tf.keras.layers.BatchNormalization()(xr)\n",
    "    xr = tf.keras.layers.ReLU()(xr)\n",
    "    xr = tf.keras.layers.Conv2D(32, 3, activation='linear', padding='same', kernel_regularizer=l2_weight_decay, use_bias=use_bias)(xr)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = tf.keras.layers.Conv2D(kernel_size=1, filters=32, strides=1, padding=\"same\",\n",
    "                               kernel_regularizer=l2_weight_decay, use_bias=use_bias)(x)\n",
    "    x = tf.keras.layers.Add()([x, xr])\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    xr = tf.keras.layers.ReLU()(x)\n",
    "    xr = tf.keras.layers.Conv2D(32, 3, activation='linear', padding='same', kernel_regularizer=l2_weight_decay, use_bias=use_bias)(xr)\n",
    "    xr = tf.keras.layers.BatchNormalization()(xr)\n",
    "    xr = tf.keras.layers.ReLU()(xr)\n",
    "    xr = tf.keras.layers.Conv2D(32, 3, activation='linear', padding='same', kernel_regularizer=l2_weight_decay, use_bias=use_bias)(xr)\n",
    "    x = tf.keras.layers.Add()([x, xr])\n",
    "\n",
    "    # fourth block\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    xr = tf.keras.layers.ReLU()(x)\n",
    "    xr = tf.keras.layers.Conv2D(64, 3, strides=(2, 2), activation='linear', padding='same',\n",
    "                                kernel_regularizer=l2_weight_decay, use_bias=use_bias)(xr)\n",
    "    xr = tf.keras.layers.BatchNormalization()(xr)\n",
    "    xr = tf.keras.layers.ReLU()(xr)\n",
    "    xr = tf.keras.layers.Conv2D(64, 3, activation='linear', padding='same', kernel_regularizer=l2_weight_decay, use_bias=use_bias)(xr)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = tf.keras.layers.Conv2D(kernel_size=1, filters=64, strides=1, padding=\"same\",\n",
    "                               kernel_regularizer=l2_weight_decay, use_bias=use_bias)(x)\n",
    "    x = tf.keras.layers.Add()([x, xr])\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    xr = tf.keras.layers.ReLU()(x)\n",
    "    xr = tf.keras.layers.Conv2D(64, 3, activation='linear', padding='same', kernel_regularizer=l2_weight_decay, use_bias=use_bias)(xr)\n",
    "    xr = tf.keras.layers.BatchNormalization()(xr)\n",
    "    xr = tf.keras.layers.ReLU()(xr)\n",
    "    xr = tf.keras.layers.Conv2D(64, 3, activation='linear', padding='same', kernel_regularizer=l2_weight_decay, use_bias=use_bias)(xr)\n",
    "    x = tf.keras.layers.Add()([x, xr])\n",
    "\n",
    "    # fifth block\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    xr = tf.keras.layers.ReLU()(x)\n",
    "    xr = tf.keras.layers.Conv2D(128, 3, strides=(2, 2), activation='linear', padding='same',\n",
    "                                kernel_regularizer=l2_weight_decay, use_bias=use_bias)(xr)\n",
    "    xr = tf.keras.layers.BatchNormalization()(xr)\n",
    "    xr = tf.keras.layers.ReLU()(xr)\n",
    "    xr = tf.keras.layers.Conv2D(128, 3, activation='linear', padding='same', kernel_regularizer=l2_weight_decay, use_bias=use_bias)(xr)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = tf.keras.layers.Conv2D(kernel_size=1, filters=128, strides=1, padding=\"same\",\n",
    "                               kernel_regularizer=l2_weight_decay, use_bias=use_bias)(x)\n",
    "    x = tf.keras.layers.Add()([x, xr])\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    xr = tf.keras.layers.ReLU()(x)\n",
    "    xr = tf.keras.layers.Conv2D(128, 3, activation='linear', padding='same', kernel_regularizer=l2_weight_decay, use_bias=use_bias)(xr)\n",
    "    xr = tf.keras.layers.BatchNormalization()(xr)\n",
    "    xr = tf.keras.layers.ReLU()(xr)\n",
    "    xr = tf.keras.layers.Conv2D(128, 3, activation='linear', padding='same', kernel_regularizer=l2_weight_decay, use_bias=use_bias)(xr)\n",
    "    x = tf.keras.layers.Add()([x, xr])\n",
    "\n",
    "    x = tf.keras.layers.MaxPooling2D((18, 1), padding='same')(x)\n",
    "    x = tf.keras.layers.Flatten(name='flat')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    emb_mel = tf.keras.layers.Dense(128, kernel_regularizer=l2_weight_decay, name='emb_mel', use_bias=use_bias)(x)\n",
    "\n",
    "    # prepare output\n",
    "    x = tf.keras.layers.Concatenate(axis=-1)([emb_fft, emb_mel])\n",
    "    output = SCAdaCos(n_classes=num_classes*2, n_subclusters=n_subclusters)([x, y, label_input])\n",
    "    loss_output = tf.keras.layers.Lambda(lambda x: tf.stack(x, axis=-1))([output, y])\n",
    "\n",
    "    return data_input, label_input, loss_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling MaxPooling2D.call().\n\n\u001b[1mComputed output size would be negative. Received: `inputs.shape=[None 0 257 16]` and `pool_size=[3 3]`.\u001b[0m\n\nArguments received by MaxPooling2D.call():\n  • args=('<KerasTensor shape=(None, 0, 257, 16), dtype=float32, sparse=False, name=keras_tensor_69>',)\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_emb_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 54\u001b[0m, in \u001b[0;36mmodel_emb_cnn\u001b[0;34m(num_classes, raw_dim, n_subclusters, use_bias)\u001b[0m\n\u001b[1;32m     52\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mBatchNormalization()(x)\n\u001b[1;32m     53\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mReLU()(x)\n\u001b[0;32m---> 54\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMaxPooling2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# second block\u001b[39;00m\n\u001b[1;32m     57\u001b[0m xr \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mReLU()(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/src/ops/operation_utils.py:138\u001b[0m, in \u001b[0;36mcompute_pooling_output_shape\u001b[0;34m(input_shape, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(output_spatial_shape)):\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m none_dims \u001b[38;5;129;01mand\u001b[39;00m output_spatial_shape[i] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 138\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    139\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputed output size would be negative. Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`inputs.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` and `pool_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpool_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m             )\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m padding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    143\u001b[0m     output_spatial_shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor((spatial_shape \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m strides) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling MaxPooling2D.call().\n\n\u001b[1mComputed output size would be negative. Received: `inputs.shape=[None 0 257 16]` and `pool_size=[3 3]`.\u001b[0m\n\nArguments received by MaxPooling2D.call():\n  • args=('<KerasTensor shape=(None, 0, 257, 16), dtype=float32, sparse=False, name=keras_tensor_69>',)\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "model_emb_cnn([1], 128, 3, use_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
